{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9ae13f0-51cd-464f-b586-9434db1e8896",
   "metadata": {},
   "source": [
    "# Text mining : Extracting keywords from papers\n",
    "## Abstract\n",
    "Text mining consists in extractings useful information from text data.\n",
    "\n",
    "We will first reproduce the text mining used by VOSviewer, a popular tool for analysing bibliography networks (https://arxiv.org/pdf/1109.2058).\n",
    "\n",
    "Here are their steps related to text mining :\n",
    "<blockquote cite=\"http://www.worldwildlife.org/who/index.html\">\n",
    "    \n",
    "1. <strong>Identification of noun phrases.</strong> The approach that we take is similar to what is\n",
    "reported in an earlier paper (Van Eck, Waltman, Noyons, & Buter, 2010). We first\n",
    "perform part-of-speech tagging (i.e., identification of verbs, nouns, adjectives, etc.).\n",
    "The Apache OpenNLP toolkit (http://incubator.apache.org/opennlp/) is used for this\n",
    "purpose. We then use a linguistic filter to identify noun phrases. Our filter selects all\n",
    "word sequences that consist exclusively of nouns and adjectives and that end with a\n",
    "noun (e.g., paper, visualization, interesting result, and text mining, but not degrees of\n",
    "freedom and highly cited publication). Finally, we convert plural noun phrases into\n",
    "singular ones.\n",
    "\n",
    "2. <p>\n",
    "        <strong>Selection of the most relevant noun phrases.</strong> The selected noun phrases are referred to\n",
    "        as terms. We have developed a new technique for selecting the most relevant noun\n",
    "        phrases. The essence of this technique is as follows. For each noun phrase, the\n",
    "        distribution of (second-order) co-occurrences over all noun phrases is determined.\n",
    "    <p/>\n",
    "    <p>\n",
    "        This distribution is compared with the overall distribution of co-occurrences over\n",
    "        noun phrases. The larger the difference between the two distributions (measured using\n",
    "        the Kullback-Leibler distance), the higher the relevance of a noun phrase. Intuitively,\n",
    "        the idea is that noun phrases with a low relevance (or noun phrases with a general\n",
    "        meaning), such as paper, interesting result, and new method, have a more or less\n",
    "        equal distribution of their (second-order) co-occurrences. On the other hand, noun\n",
    "        phrases with a high relevance (or noun phrases with a specific meaning), such as\n",
    "        visualization, text mining, and natural language processing, have a distribution of\n",
    "        their (second-order) co-occurrences that is significantly biased towards certain other\n",
    "        noun phrases. Hence, it is assumed that in a co-occurrence network noun phrases with\n",
    "        a high relevance are grouped together into clusters. Each cluster may be seen as a\n",
    "        topic.\n",
    "    </p>\n",
    "</blockquote>\n",
    "\n",
    "We  won't be using Apache OpenNLP to perform POS tagging like they did, because there was an issue in the later build that we tried, and it was inconvenient to use because it's a Java library. Instead, we will first be using nltk, which is a well liked Python package for NLP.\n",
    "\n",
    "Aside from nltk, we might consider those other promising NLP tools :\n",
    "- Google Parsey McParseface\n",
    "- Stanford CoreNLP\n",
    "- Amazon Comprehend\n",
    "- Flair\n",
    "- Gensim\n",
    "- Spacy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdcd0b4-7f77-44b4-81a0-e8ee745c06f9",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We first import the dependencies, and download the models used for pos tagging and tokenising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e3472d3-8e46-4624-9a10-73041747ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import polars as pl\n",
    "from pprint import pp\n",
    "import os\n",
    "import spacy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "adj_tags = [\"JJ\", \"JJR\", \"JJS\"]\n",
    "noun_tags = [\"NN\", \"NNS\", \"NNP\", \"NNPS\"]\n",
    "\n",
    "def df(name: str) -> str:\n",
    "    return os.path.join(\"dataframes\", name + \".parquet\")\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import jax.experimental.sparse as sparse\n",
    "import jax\n",
    "from jax.experimental.sparse import sparsify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5324dcb1-f243-4019-a623-0b40bf853f59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/moonlyss/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/moonlyss/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package tagsets to /home/moonlyss/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/moonlyss/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/moonlyss/.local/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /home/moonlyss/.local/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (69.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/moonlyss/.local/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/moonlyss/.local/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/moonlyss/.local/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/moonlyss/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/moonlyss/.local/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.17.2)\n",
      "Requirement already satisfied: wrapt in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/moonlyss/conda/envs/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')  # pos tagger\n",
    "nltk.download('punkt')  # tokenizer\n",
    "nltk.download('tagsets')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689b8225-5fde-41c5-b8b5-a3c21d9fb652",
   "metadata": {},
   "source": [
    "##  Identification of noun phrases\n",
    "### Evaluating part-of-speech tagging (POS)\n",
    "Let's start with taking an abstract from our BIM papers dataset and applying POS tagging with nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e17ab462-6483-4def-bfb8-4a0e28ec2254",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful tagging : \n",
      "[('Abstract', 'NN'),\n",
      " (':', ':'),\n",
      " ('The', 'DT'),\n",
      " ('development', 'NN'),\n",
      " ('of', 'IN'),\n",
      " ('the', 'DT'),\n",
      " ('digital', 'JJ'),\n",
      " ('economy', 'NN'),\n",
      " ('has', 'VBZ'),\n",
      " ('changed', 'VBN')]\n",
      "\n",
      "Tagging failure, 'stricter' should be an adjective (JJ) :\n",
      "[('cities', 'NNS'),\n",
      " ('with', 'IN'),\n",
      " ('stricter', 'NN'),\n",
      " ('governmental', 'JJ'),\n",
      " ('environmental', 'JJ'),\n",
      " ('regulations', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "abstract = pl.scan_parquet(df(\"papers\")).first().collect()[0, \"Abstract\"]\n",
    "tokens = nltk.word_tokenize(abstract)\n",
    "tags = nltk.pos_tag(tokens)\n",
    "print(\"Successful tagging : \")\n",
    "pp(tags[:10])\n",
    "print(\"\\nTagging failure, 'stricter' should be an adjective (JJ) :\")\n",
    "pp(tags[219:225])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c57b3ee-51fc-416d-921e-2b532c57dfb1",
   "metadata": {},
   "source": [
    "The result seems convincing but not perfect. We can move on to the filtering and extraction of noun phrases.\n",
    "\n",
    "Method used by VOSviewer :\n",
    "<blockquote>\n",
    "We then use a linguistic filter to identify noun phrases. Our filter selects all\n",
    "word sequences that consist exclusively of nouns and adjectives and that end with a\n",
    "noun (e.g., paper, visualization, interesting result, and text mining, but not degrees of\n",
    "freedom and highly cited publication). Finally, we convert plural noun phrases into\n",
    "singular ones.  \n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "121d7991-103e-4769-90d2-250afc9e323a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (75, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>noun_phrase</th><th>tags</th></tr><tr><td>str</td><td>list[cat]</td></tr></thead><tbody><tr><td>&quot;fixed effect model&quot;</td><td>[&quot;JJ&quot;, &quot;NN&quot;, &quot;NN&quot;]</td></tr><tr><td>&quot;other robustness tests&quot;</td><td>[&quot;JJ&quot;, &quot;NN&quot;, &quot;NNS&quot;]</td></tr><tr><td>&quot;study&quot;</td><td>[&quot;NN&quot;]</td></tr><tr><td>&quot;urban level&quot;</td><td>[&quot;JJ&quot;, &quot;NN&quot;]</td></tr><tr><td>&quot;super-efficient slack-based me…</td><td>[&quot;JJ&quot;, &quot;JJ&quot;, &quot;NN&quot;]</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;cities&quot;</td><td>[&quot;NNS&quot;]</td></tr><tr><td>&quot;sdgs&quot;</td><td>[&quot;NNP&quot;]</td></tr><tr><td>&quot;mechanism analysis&quot;</td><td>[&quot;NN&quot;, &quot;NN&quot;]</td></tr><tr><td>&quot;urban gee&quot;</td><td>[&quot;JJ&quot;, &quot;NNP&quot;]</td></tr><tr><td>&quot;energy structure transformatio…</td><td>[&quot;NN&quot;, &quot;NN&quot;, &quot;NN&quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (75, 2)\n",
       "┌─────────────────────────────────┬─────────────────────┐\n",
       "│ noun_phrase                     ┆ tags                │\n",
       "│ ---                             ┆ ---                 │\n",
       "│ str                             ┆ list[cat]           │\n",
       "╞═════════════════════════════════╪═════════════════════╡\n",
       "│ fixed effect model              ┆ [\"JJ\", \"NN\", \"NN\"]  │\n",
       "│ other robustness tests          ┆ [\"JJ\", \"NN\", \"NNS\"] │\n",
       "│ study                           ┆ [\"NN\"]              │\n",
       "│ urban level                     ┆ [\"JJ\", \"NN\"]        │\n",
       "│ super-efficient slack-based me… ┆ [\"JJ\", \"JJ\", \"NN\"]  │\n",
       "│ …                               ┆ …                   │\n",
       "│ cities                          ┆ [\"NNS\"]             │\n",
       "│ sdgs                            ┆ [\"NNP\"]             │\n",
       "│ mechanism analysis              ┆ [\"NN\", \"NN\"]        │\n",
       "│ urban gee                       ┆ [\"JJ\", \"NNP\"]       │\n",
       "│ energy structure transformatio… ┆ [\"NN\", \"NN\", \"NN\"]  │\n",
       "└─────────────────────────────────┴─────────────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "           \n",
    "filtered_q = (\n",
    "    pl.DataFrame(tags, orient=\"row\", schema={\"token\": pl.String, \"tag\": pl.Categorical(ordering=\"physical\")}).lazy()\n",
    "    .select(\n",
    "        pl.arange(0, pl.len()).alias(\"pos\"),\n",
    "        pl.all(),\n",
    "        pl.col(\"tag\").is_in(adj_tags + noun_tags).alias(\"keep\")  # keep only nouns and adjectives\n",
    "    )                  \n",
    "    .with_columns(group_id=pl.col(\"keep\").rle_id())\n",
    "    .filter(pl.col(\"keep\") == True)\n",
    "    .select(\n",
    "        \"pos\", \n",
    "        \"token\",\n",
    "        \"tag\",\n",
    "        \"group_id\")\n",
    "    .group_by(\"group_id\").agg(\"pos\", \"token\", \"tag\")\n",
    "    \n",
    "    # Keep only word sequences that end with a noun\n",
    "    .with_columns(\n",
    "        pl.col(\"tag\").list.eval(pl.element().is_in(adj_tags)).list.reverse().alias(\"adjs_reversed\")\n",
    "    )\n",
    "    .with_columns(\n",
    "        (pl.col(\"adjs_reversed\").list.len() - 1 - pl.col(\"adjs_reversed\").list.arg_min()).alias(\"last_noun_pos\"),\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(\"token\").list.head(pl.col(\"last_noun_pos\") + 1)\n",
    "    )\n",
    "    \n",
    "    .filter(~pl.col(\"adjs_reversed\").list.all())  # remove groups that are only adjectives\n",
    "    .select(\n",
    "        pl.col(\"token\").list.join(\" \").str.to_lowercase().alias(\"noun_phrase\"),\n",
    "        pl.col(\"tag\").alias(\"tags\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "with pl.StringCache():\n",
    "    pl.Series(\"tags_order\", [\"NN\", \"NNS\", \"JJ\"], pl.Categorical)\n",
    "    filtered = filtered_q.collect()\n",
    "filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a797440a-3991-4a9d-b32f-f8911ca30e81",
   "metadata": {},
   "source": [
    "Now that we have a working solution for one text, let's adapt it to make it work on the complete dataframe of papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "693c59b0-2684-4317-b1a0-61aefcebbe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable = ['ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "835ac3e3-ef65-4297-a317-591c5e335f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My my PRON PRP$ poss Xx True True\n",
      "beautiful beautiful ADJ JJ amod xxxx True False\n",
      "dogs dog NOUN NNS nsubj xxxx True False\n",
      "are be AUX VBP ROOT xxx True True\n",
      "better well ADJ JJR acomp xxxx True False\n",
      "than than ADP IN prep xxxx True True\n",
      "yours your NOUN NNS pobj xxxx True True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "doc = nlp(\"My beautiful dogs are better than yours\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac523ab-910d-4b5d-8865-f75dd98fa89d",
   "metadata": {},
   "source": [
    "We now create a dataframe where we apply the strategy of VOSviewer to all papers in our dataset.\n",
    "Resulting dataframes has the following columns :\n",
    "- noun_phrase\n",
    "- paper_ids : multiple noun phrase appearances in paper will result in several ids appearances\n",
    "- tags\n",
    "- count\n",
    "- paper_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "id": "e8a68fa6-b0a9-4bdb-8e99-02574db8e63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.28857159614563\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (872, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>term</th><th>paper_ids</th><th>count</th><th>tags</th><th>paper_count</th></tr><tr><td>u32</td><td>str</td><td>list[i64]</td><td>u32</td><td>list[cat]</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>&quot;technology&quot;</td><td>[481, 413, … 311]</td><td>231</td><td>[&quot;NNS&quot;]</td><td>159</td></tr><tr><td>1</td><td>&quot;sustainability&quot;</td><td>[236, 358, … 116]</td><td>199</td><td>[&quot;NN&quot;]</td><td>142</td></tr><tr><td>2</td><td>&quot;result&quot;</td><td>[164, 172, … 335]</td><td>152</td><td>[&quot;NNS&quot;]</td><td>125</td></tr><tr><td>3</td><td>&quot;development&quot;</td><td>[497, 169, … 241]</td><td>143</td><td>[&quot;NNS&quot;, &quot;JJ&quot;]</td><td>117</td></tr><tr><td>4</td><td>&quot;research&quot;</td><td>[444, 378, … 283]</td><td>150</td><td>[&quot;NN&quot;]</td><td>112</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>867</td><td>&quot;firm green innovation&quot;</td><td>[49, 49, … 49]</td><td>6</td><td>[&quot;NN&quot;, &quot;JJ&quot;, &quot;NN&quot;]</td><td>1</td></tr><tr><td>868</td><td>&quot;economic digitalization&quot;</td><td>[2, 2, … 2]</td><td>6</td><td>[&quot;JJ&quot;, &quot;NN&quot;]</td><td>1</td></tr><tr><td>869</td><td>&quot;dm&quot;</td><td>[216, 216, … 216]</td><td>6</td><td>[&quot;NN&quot;]</td><td>1</td></tr><tr><td>870</td><td>&quot;high-quality green development&quot;</td><td>[214, 214, … 214]</td><td>6</td><td>[&quot;NN&quot;, &quot;NN&quot;, &quot;NN&quot;]</td><td>1</td></tr><tr><td>871</td><td>&quot;ua&quot;</td><td>[120, 120, … 120]</td><td>6</td><td>[&quot;NNP&quot;]</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (872, 6)\n",
       "┌─────┬─────────────────────────┬───────────────────┬───────┬────────────────────┬─────────────┐\n",
       "│ id  ┆ term                    ┆ paper_ids         ┆ count ┆ tags               ┆ paper_count │\n",
       "│ --- ┆ ---                     ┆ ---               ┆ ---   ┆ ---                ┆ ---         │\n",
       "│ u32 ┆ str                     ┆ list[i64]         ┆ u32   ┆ list[cat]          ┆ u32         │\n",
       "╞═════╪═════════════════════════╪═══════════════════╪═══════╪════════════════════╪═════════════╡\n",
       "│ 0   ┆ technology              ┆ [481, 413, … 311] ┆ 231   ┆ [\"NNS\"]            ┆ 159         │\n",
       "│ 1   ┆ sustainability          ┆ [236, 358, … 116] ┆ 199   ┆ [\"NN\"]             ┆ 142         │\n",
       "│ 2   ┆ result                  ┆ [164, 172, … 335] ┆ 152   ┆ [\"NNS\"]            ┆ 125         │\n",
       "│ 3   ┆ development             ┆ [497, 169, … 241] ┆ 143   ┆ [\"NNS\", \"JJ\"]      ┆ 117         │\n",
       "│ 4   ┆ research                ┆ [444, 378, … 283] ┆ 150   ┆ [\"NN\"]             ┆ 112         │\n",
       "│ …   ┆ …                       ┆ …                 ┆ …     ┆ …                  ┆ …           │\n",
       "│ 867 ┆ firm green innovation   ┆ [49, 49, … 49]    ┆ 6     ┆ [\"NN\", \"JJ\", \"NN\"] ┆ 1           │\n",
       "│ 868 ┆ economic digitalization ┆ [2, 2, … 2]       ┆ 6     ┆ [\"JJ\", \"NN\"]       ┆ 1           │\n",
       "│ 869 ┆ dm                      ┆ [216, 216, … 216] ┆ 6     ┆ [\"NN\"]             ┆ 1           │\n",
       "│ 870 ┆ high-quality green      ┆ [214, 214, … 214] ┆ 6     ┆ [\"NN\", \"NN\", \"NN\"] ┆ 1           │\n",
       "│     ┆ development             ┆                   ┆       ┆                    ┆             │\n",
       "│ 871 ┆ ua                      ┆ [120, 120, … 120] ┆ 6     ┆ [\"NNP\"]            ┆ 1           │\n",
       "└─────┴─────────────────────────┴───────────────────┴───────┴────────────────────┴─────────────┘"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# from flair.nn import Classifier\n",
    "# from flair.data import Sentence\n",
    "\n",
    "def nltk_tags(col: str, alias: str | None=None):\n",
    "    return (pl.col(col).alias(alias if alias is not None else col.lower() + \"_tokens_tags\")\n",
    "        .map_elements(nltk.word_tokenize, return_dtype=pl.List(pl.String), strategy=\"thread_local\")\n",
    "        .map_batches(lambda series : pl.Series(nltk.pos_tag_sents(series)), return_dtype=pl.List(pl.List(pl.String)))\n",
    "            # .cast(pl.Struct({\"yo\": pl.String, \"y\": pl.Categorical}))\n",
    "           )\n",
    "from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# # load the model\n",
    "# tagger = Classifier.load('pos-fast')\n",
    "\n",
    "# # make a sentence\n",
    "# sentence = Sentence('Dirk went to the store.')\n",
    "\n",
    "# # predict NER tags\n",
    "skip_words = [\"abstract\", \"%\",\n",
    "              \"paper\", \"study\", \"use\"\n",
    "             ]\n",
    "t0 = time.time()\n",
    "# tagger.predict(sentence)\n",
    "\n",
    "# print sentence with predicted tags\n",
    "q = (\n",
    "    pl.scan_parquet(df(\"papers\"))\n",
    "    .select(\n",
    "        pl.col(\"Id\").alias(\"paper_id\"), \n",
    "        pl.concat_list(\n",
    "            pl.col(\"Subject\"),\n",
    "            pl.col(\"Abstract\"),\n",
    "            pl.col(\"Keywords\")\n",
    "        ).alias(\"text\"),   \n",
    "    )\n",
    "    .explode(\"text\")\n",
    "    .with_columns(\n",
    "        pl.arange(0, pl.len()).alias(\"text_id\"),\n",
    "        nltk_tags(\"text\", \"tokens_tags\"),\n",
    "    )\n",
    "    .explode(\"tokens_tags\")\n",
    "    .select(\n",
    "        pl.exclude(\"tokens_tags\"),\n",
    "        pl.col(\"tokens_tags\").list.get(0).alias(\"token\"),\n",
    "        pl.col(\"tokens_tags\").list.get(1).alias(\"tag\").cast(pl.Categorical)\n",
    "    ) \n",
    "    .with_columns(\n",
    "        pl.col(\"tag\").is_in(adj_tags + noun_tags).alias(\"keep\")  # keep only nouns and adjectives\n",
    "    )                  \n",
    "    .with_columns(group_id=pl.col(\"keep\").rle_id())\n",
    "    .filter(pl.col(\"keep\") == True)\n",
    "    \n",
    "    # Lemmatize plural forms to singular form\n",
    "    .with_columns(\n",
    "        pl.struct(\"token\", \"tag\").map_elements(lambda t: lemmatizer.lemmatize(t[\"token\"]) if t[\"tag\"] in noun_tags else t[\"token\"], return_dtype=pl.String).alias(\"token\"),\n",
    "    )\n",
    "    .group_by(\"paper_id\", \"text_id\", \"group_id\").agg(\"token\", \"tag\")\n",
    "    \n",
    "    # Keep only word sequences that end with a noun\n",
    "    .with_columns(\n",
    "        pl.col(\"tag\").list.eval(pl.element().is_in(adj_tags)).list.reverse().alias(\"adjs_reversed\")\n",
    "    )\n",
    "    .with_columns(\n",
    "        (pl.col(\"adjs_reversed\").list.len() - 1 - pl.col(\"adjs_reversed\").list.arg_min()).alias(\"last_noun_pos\"),\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(\"token\").list.head(pl.col(\"last_noun_pos\") + 1)\n",
    "    )\n",
    "    .filter(~pl.col(\"adjs_reversed\").list.all())  # remove groups that are only adjectives\n",
    "\n",
    "    # Final data preparation\n",
    "    .select(\n",
    "        pl.col(\"paper_id\").alias(\"paper_ids\"),\n",
    "        pl.col(\"token\").list.join(\" \").str.to_lowercase().alias(\"term\"),\n",
    "        pl.col(\"tag\").alias(\"tags\"),\n",
    "    )\n",
    "    .filter(~pl.col(\"term\").is_in(skip_words), )\n",
    "    .group_by(\"term\").agg(\n",
    "        pl.col(\"paper_ids\"), pl.col(\"term\").len().alias(\"count\"),\n",
    "        pl.col(\"tags\").first()\n",
    "    )\n",
    "    .filter(pl.col(\"count\") > 5)  # keep only words that appear 5 times\n",
    "    .with_columns(pl.col(\"paper_ids\").list.unique().list.len().alias(\"paper_count\"))\n",
    "    \n",
    "    .sort(\"paper_count\", \"count\", descending=True)\n",
    "    .select(\n",
    "        pl.arange(0, pl.len(), dtype=pl.UInt32).alias(\"id\"),\n",
    "        pl.all()\n",
    "    )\n",
    ")\n",
    "\n",
    "res = q.collect()\n",
    "# res = q.fetch(50)\n",
    "print(time.time() - t0)\n",
    "res.write_parquet(df(\"terms_from_subject_abstract_keywords\"))\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "id": "e7880717-a67b-4e83-9a40-787df6070367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (11_582, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>term</th><th>paper_id</th><th>count</th></tr><tr><td>u32</td><td>cat</td><td>i64</td><td>u32</td></tr></thead><tbody><tr><td>507</td><td>&quot;robustness test&quot;</td><td>229</td><td>1</td></tr><tr><td>758</td><td>&quot;supply chain management&quot;</td><td>253</td><td>2</td></tr><tr><td>273</td><td>&quot;regulation&quot;</td><td>3</td><td>1</td></tr><tr><td>152</td><td>&quot;circular economy&quot;</td><td>353</td><td>2</td></tr><tr><td>79</td><td>&quot;aim&quot;</td><td>423</td><td>1</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>21</td><td>&quot;finding&quot;</td><td>24</td><td>1</td></tr><tr><td>56</td><td>&quot;benefit&quot;</td><td>249</td><td>1</td></tr><tr><td>831</td><td>&quot;dci&quot;</td><td>241</td><td>7</td></tr><tr><td>210</td><td>&quot;ability&quot;</td><td>175</td><td>1</td></tr><tr><td>12</td><td>&quot;industry&quot;</td><td>211</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (11_582, 4)\n",
       "┌─────┬─────────────────────────┬──────────┬───────┐\n",
       "│ id  ┆ term                    ┆ paper_id ┆ count │\n",
       "│ --- ┆ ---                     ┆ ---      ┆ ---   │\n",
       "│ u32 ┆ cat                     ┆ i64      ┆ u32   │\n",
       "╞═════╪═════════════════════════╪══════════╪═══════╡\n",
       "│ 507 ┆ robustness test         ┆ 229      ┆ 1     │\n",
       "│ 758 ┆ supply chain management ┆ 253      ┆ 2     │\n",
       "│ 273 ┆ regulation              ┆ 3        ┆ 1     │\n",
       "│ 152 ┆ circular economy        ┆ 353      ┆ 2     │\n",
       "│ 79  ┆ aim                     ┆ 423      ┆ 1     │\n",
       "│ …   ┆ …                       ┆ …        ┆ …     │\n",
       "│ 21  ┆ finding                 ┆ 24       ┆ 1     │\n",
       "│ 56  ┆ benefit                 ┆ 249      ┆ 1     │\n",
       "│ 831 ┆ dci                     ┆ 241      ┆ 7     │\n",
       "│ 210 ┆ ability                 ┆ 175      ┆ 1     │\n",
       "│ 12  ┆ industry                ┆ 211      ┆ 1     │\n",
       "└─────┴─────────────────────────┴──────────┴───────┘"
      ]
     },
     "execution_count": 844,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "\n",
    "df_kw_paper = (\n",
    "    pl.scan_parquet(df(\"terms_from_subject_abstract_keywords\"))\n",
    "    .explode(\"paper_ids\")\n",
    "    .with_columns(pl.col(\"term\").cast(pl.Categorical))\n",
    "    .group_by(\"id\", \"term\", \"paper_ids\").agg(pl.col(\"term\").len().alias(\"count\"),\n",
    "                                       # pl.col(\"tags\").first()\n",
    "                                      )\n",
    "    .rename({\"paper_ids\": \"paper_id\"})\n",
    ").collect()\n",
    "df_kw_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "id": "a357f93b-cb3a-4409-9485-b9a24a7c2ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 3, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint32)"
      ]
     },
     "execution_count": 878,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df_kw_paper[\"count\"].to_numpy()\n",
    "indices = np.concatenate(df_kw_paper.select(pl.concat_list(\"id\", \"paper_id\").alias(\"indices\"))[\"indices\"].to_numpy()).reshape(len(df_kw_paper), 2)\n",
    "kw_paper = sparse.BCOO((data, indices), shape=(872, 543)).todense()\n",
    "kw_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "532007b9-7390-478c-ba77-3bc0ada8f4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (174, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>term</th><th>paper_id</th><th>count</th></tr><tr><td>i64</td><td>cat</td><td>i64</td><td>u32</td></tr></thead><tbody><tr><td>70</td><td>&quot;chapter&quot;</td><td>366</td><td>6</td></tr><tr><td>700</td><td>&quot;intelligent building&quot;</td><td>117</td><td>6</td></tr><tr><td>18</td><td>&quot;digitalization&quot;</td><td>42</td><td>8</td></tr><tr><td>732</td><td>&quot;green finance&quot;</td><td>64</td><td>12</td></tr><tr><td>629</td><td>&quot;urban agglomeration&quot;</td><td>92</td><td>8</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>851</td><td>&quot;di&quot;</td><td>99</td><td>6</td></tr><tr><td>852</td><td>&quot;high-quality green development&quot;</td><td>214</td><td>6</td></tr><tr><td>817</td><td>&quot;micrm&quot;</td><td>373</td><td>9</td></tr><tr><td>823</td><td>&quot;social-ecological resilience&quot;</td><td>118</td><td>8</td></tr><tr><td>867</td><td>&quot;ict development&quot;</td><td>238</td><td>6</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (174, 4)\n",
       "┌─────┬────────────────────────────────┬──────────┬───────┐\n",
       "│ id  ┆ term                           ┆ paper_id ┆ count │\n",
       "│ --- ┆ ---                            ┆ ---      ┆ ---   │\n",
       "│ i64 ┆ cat                            ┆ i64      ┆ u32   │\n",
       "╞═════╪════════════════════════════════╪══════════╪═══════╡\n",
       "│ 70  ┆ chapter                        ┆ 366      ┆ 6     │\n",
       "│ 700 ┆ intelligent building           ┆ 117      ┆ 6     │\n",
       "│ 18  ┆ digitalization                 ┆ 42       ┆ 8     │\n",
       "│ 732 ┆ green finance                  ┆ 64       ┆ 12    │\n",
       "│ 629 ┆ urban agglomeration            ┆ 92       ┆ 8     │\n",
       "│ …   ┆ …                              ┆ …        ┆ …     │\n",
       "│ 851 ┆ di                             ┆ 99       ┆ 6     │\n",
       "│ 852 ┆ high-quality green development ┆ 214      ┆ 6     │\n",
       "│ 817 ┆ micrm                          ┆ 373      ┆ 9     │\n",
       "│ 823 ┆ social-ecological resilience   ┆ 118      ┆ 8     │\n",
       "│ 867 ┆ ict development                ┆ 238      ┆ 6     │\n",
       "└─────┴────────────────────────────────┴──────────┴───────┘"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.filter(pl.col(\"count\") > 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "6051b848-574a-4b40-be63-a610ae015966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1, 1, 0, 0],\n",
       "       [1, 2, 1, 0],\n",
       "       [0, 1, 2, 1],\n",
       "       [0, 0, 1, 1]], dtype=int32)"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dimensions for the dot product (contracting dimensions)\n",
    "# Since numpy.dot(A, B) sums over the last axis of A and the second-to-last of B,\n",
    "# these are the dimensions to contract.\n",
    "dimension_numbers = (([1], [0]), ([], []))\n",
    "\n",
    "@jax.jit\n",
    "def get_cooccurences(a):\n",
    "    return a @ a.T\n",
    "\n",
    "@jax.jit\n",
    "def get_second_order_cooccurences(a):\n",
    "    fo = a @ a.T\n",
    "    return fo @ fo  # no need to transpose because symetric\n",
    "\n",
    "\n",
    "test = jnp.array([1,1,0,0,1,2,1,0,0,1,2,1,0,0,1,1]).reshape(4,4)\n",
    "# test =get_cooccurences(test)  # second order\n",
    "# test = get_cooccurences(test)  # third order\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "id": "044d8247-2261-417a-ba24-b8d0e09a5ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10277223587036133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([[467,  95,  37, ...,   6,   0,   6],\n",
       "       [ 95, 369,  47, ...,   0,   0,   6],\n",
       "       [ 37,  47, 212, ...,   0,   6,   0],\n",
       "       ...,\n",
       "       [  6,   0,   0, ...,  36,   0,   0],\n",
       "       [  0,   0,   6, ...,   0,  36,   0],\n",
       "       [  6,   6,   0, ...,   0,   0,  36]], dtype=uint32)"
      ]
     },
     "execution_count": 901,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "cooccurences = get_cooccurences(kw_paper)\n",
    "print(time.time() - t0)\n",
    "cooccurences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "1bb5cfb4-5ff8-4219-b75c-560509886543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027343034744262695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([[467,  95,  37, ...,   6,   0,   6],\n",
       "       [ 95, 369,  47, ...,   0,   0,   0],\n",
       "       [ 37,  47, 212, ...,   6,   6,   0],\n",
       "       ...,\n",
       "       [  6,   0,   6, ...,  36,   0,   0],\n",
       "       [  0,   0,   6, ...,   0,  36,   0],\n",
       "       [  6,   0,   0, ...,   0,   0,  36]], dtype=uint32)"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "res = jnp.dot(dense, dense.T)\n",
    "print(time.time() - t0)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "id": "823c4e0b-96d6-4b3f-a70b-6b70f3644a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[410281, 219728, 105304, ...,   9600,   1962,   7758],\n",
       "       [219728, 292514,  96887, ...,   4458,   2046,   6966],\n",
       "       [105304,  96887, 109220, ...,   2622,   4074,   2496],\n",
       "       ...,\n",
       "       [  9600,   4458,   2622, ...,   4104,     36,     72],\n",
       "       [  1962,   2046,   4074, ...,     36,   2952,      0],\n",
       "       [  7758,   6966,   2496, ...,     72,      0,   2988]],      dtype=uint32)"
      ]
     },
     "execution_count": 879,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_order_cooccurences = get_cooccurences(cooccurences)\n",
    "second_order_cooccurences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd152d0d-6150-45f4-887f-4ad64c8beb5d",
   "metadata": {},
   "source": [
    "Compute second order cooccurences of terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "id": "e00193b0-9a86-4840-9414-1474549f3a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of keywords that are not cooccuring on second order : 1587\n",
      "number of keywords that are cooccuring :  377733\n"
     ]
    }
   ],
   "source": [
    "scnd_order_cooc = get_second_order_cooccurences(kw_paper)\n",
    "print(\"number of keywords that are not cooccuring on second order :\", jnp.count_nonzero(scnd_order_cooc == 0) // 2)\n",
    "print(\"number of keywords that are cooccuring : \", jnp.count_nonzero(scnd_order_cooc != 0) // 2 - scnd_order_cooc.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e68e7b-1573-48c6-959b-6cc49f11ec9a",
   "metadata": {},
   "source": [
    "### Second order cooccurences distribution\n",
    "The distribution is computed so that each row represents the frequencies of cooccurences (i.e. sum(row) = 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "id": "0d311ce1-f701-44d4-8328-6837b9c9c697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check :\n",
      " [1.         1.         1.         0.99999994 1.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([[2.6347449e-02, 1.4110506e-02, 6.7624184e-03, ..., 6.1649334e-04,\n",
       "        1.2599582e-04, 4.9820368e-04],\n",
       "       [1.6776664e-02, 2.2334019e-02, 7.3975129e-03, ..., 3.4037707e-04,\n",
       "        1.5621612e-04, 5.3186779e-04],\n",
       "       [1.3800960e-02, 1.2697843e-02, 1.4314185e-02, ..., 3.4363478e-04,\n",
       "        5.3393142e-04, 3.2712144e-04],\n",
       "       ...,\n",
       "       [2.1324236e-02, 9.9024419e-03, 5.8241822e-03, ..., 9.1161113e-03,\n",
       "        7.9965888e-05, 1.5993178e-04],\n",
       "       [6.6385157e-03, 6.9227335e-03, 1.3784563e-02, ..., 1.2180763e-04,\n",
       "        9.9882251e-03, 0.0000000e+00],\n",
       "       [1.9778809e-02, 1.7759627e-02, 6.3634836e-03, ..., 1.8356202e-04,\n",
       "        0.0000000e+00, 7.6178242e-03]], dtype=float32)"
      ]
     },
     "execution_count": 893,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scnd_order_distrib = (scnd_order_cooc / scnd_order_cooc.sum(axis=0)).T\n",
    "print(\"check :\\n\", scnd_order_distrib.sum(axis=1)[:5]) \n",
    "scnd_order_distrib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3631fa-21ef-47dc-b5c7-e932f95ef7cc",
   "metadata": {},
   "source": [
    "### Overall cooccurences distribution\n",
    "We need the overall cooccurences distribution to compare with the second order cooccurences distribution.\n",
    "\n",
    "\"Overall\" means that instead of computing cooccurences per paper, we do it for the whole corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "219771b4-7ebd-4f6b-a753-dc75786c192d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[53361, 45969, 35112, ...,  1386,  1386,  1386],\n",
       "       [45969, 39601, 30248, ...,  1194,  1194,  1194],\n",
       "       [35112, 30248, 23104, ...,   912,   912,   912],\n",
       "       ...,\n",
       "       [ 1386,  1194,   912, ...,    36,    36,    36],\n",
       "       [ 1386,  1194,   912, ...,    36,    36,    36],\n",
       "       [ 1386,  1194,   912, ...,    36,    36,    36]], dtype=uint32)"
      ]
     },
     "execution_count": 798,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = (\n",
    "    pl.scan_parquet(df(\"terms_from_subject_abstract_keywords\"))\n",
    "    .select(\"count\")\n",
    ")\n",
    "counts = q.collect().get_column(\"count\")\n",
    "res = jnp.array(counts.to_numpy()).reshape(len(counts), 1)\n",
    "overall_cooc = get_cooccurences(res)\n",
    "overall_cooc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a352c751-7943-4337-b99c-c179672e5256",
   "metadata": {},
   "source": [
    "Same as before, we compute the distribution of coocurences on the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "id": "aa8c3713-bdab-4c32-938b-c8765bf8f6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sanity check : 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([[0.0143997 , 0.01240494, 0.00947513, ..., 0.00037402, 0.00037402,\n",
       "        0.00037402],\n",
       "       [0.0143997 , 0.01240494, 0.00947513, ..., 0.00037402, 0.00037402,\n",
       "        0.00037402],\n",
       "       [0.0143997 , 0.01240494, 0.00947513, ..., 0.00037402, 0.00037402,\n",
       "        0.00037402],\n",
       "       ...,\n",
       "       [0.0143997 , 0.01240494, 0.00947513, ..., 0.00037402, 0.00037402,\n",
       "        0.00037402],\n",
       "       [0.0143997 , 0.01240494, 0.00947513, ..., 0.00037402, 0.00037402,\n",
       "        0.00037402],\n",
       "       [0.0143997 , 0.01240494, 0.00947513, ..., 0.00037402, 0.00037402,\n",
       "        0.00037402]], dtype=float32)"
      ]
     },
     "execution_count": 842,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_distrib = overall_cooc / overall_cooc.sum(axis=1)[:, jnp.newaxis]\n",
    "print(\"sanity check :\", overall_distrib[0].sum())\n",
    "overall_distrib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c7c941-11d7-4738-b0f0-199af2b28fe7",
   "metadata": {},
   "source": [
    "### Selecting the most relevant terms based on the Kullback-Leibler divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "id": "d9b7b527-3fb0-4c42-8d14-8dde3599f313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[3.97042371e-03, 1.12220645e-04, 4.31818422e-04, ...,\n",
       "        6.56128977e-05, 1.10931942e-04, 1.86517136e-05],\n",
       "       [1.86191872e-04, 3.20369191e-03, 2.46537849e-04, ...,\n",
       "        1.56057649e-06, 8.14154919e-05, 2.94161146e-05],\n",
       "       [1.26222149e-05, 3.43378633e-06, 1.06670521e-03, ...,\n",
       "        1.26886880e-06, 3.01469117e-05, 3.07126902e-06],\n",
       "       ...,\n",
       "       [1.44813582e-03, 2.71344557e-04, 8.16599466e-04, ...,\n",
       "        2.03701574e-02, 1.70688640e-04, 7.82152056e-05],\n",
       "       [2.62085441e-03, 1.44428341e-03, 8.58112238e-04, ...,\n",
       "        1.15559313e-04, 2.31956877e-02, 3.74018215e-04],\n",
       "       [8.98757949e-04, 1.01806037e-03, 5.78379724e-04, ...,\n",
       "        5.98057231e-05, 3.74018215e-04, 1.57158710e-02]], dtype=float32)"
      ]
     },
     "execution_count": 896,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = jax.scipy.special.kl_div(scnd_order_distrib, overall_distrib)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "id": "196d0a66-d5b3-47cd-b387-acd7d77cb765",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.05283442, 0.04818851, 0.02658592, 0.03075027, 0.048304  ,\n",
       "       0.04415703, 0.04185352, 0.0425231 , 0.07724868, 0.05556743,\n",
       "       0.17190629, 0.04879113, 0.13997538, 0.10424098, 0.03371423,\n",
       "       0.07620816, 0.03667569, 0.0294241 , 0.06760576, 0.03198233,\n",
       "       0.07824764, 0.03720746, 0.0894107 , 0.03815623, 0.03346838,\n",
       "       0.03422605, 0.05207967, 0.03721029, 0.04994608, 0.02739443,\n",
       "       0.31744623, 0.0950837 , 0.06295551, 0.0612434 , 0.02322143,\n",
       "       0.04343025, 0.03029149, 0.05970468, 0.0550732 , 0.05467683,\n",
       "       0.03015793, 0.0467086 , 0.03243691, 0.11948493, 0.03801347,\n",
       "       0.07230576, 0.08613472, 0.08048847, 0.03938145, 0.09007974,\n",
       "       0.04133759, 0.03705375, 0.03054662, 0.06112577, 0.05862594,\n",
       "       0.0411022 , 0.03481007, 0.03934808, 0.04619797, 0.0401652 ,\n",
       "       0.0528256 , 0.05270232, 0.0859139 , 0.09482181, 0.04018054,\n",
       "       0.04050227, 0.03392748, 0.04489309, 0.10078646, 0.07052536,\n",
       "       0.07117409, 0.06528997, 0.06349993, 0.03224806, 0.06169534,\n",
       "       0.03600408, 0.03519495, 0.03941869, 0.02666846, 0.03847119,\n",
       "       0.05402429, 0.03368378, 0.04048004, 0.06939095, 0.18599313,\n",
       "       0.03717126, 0.04455245, 0.03872911, 0.03102669, 0.08113795,\n",
       "       0.04978253, 0.04245155, 0.04755256, 0.05438048, 0.05048746,\n",
       "       0.04330955, 0.05428084, 0.03872233, 0.03915548, 0.05173853,\n",
       "       0.04502102, 0.04319408, 0.06887457, 0.04139937, 0.05758008,\n",
       "       0.04523505, 0.06322677, 0.05364685, 0.26345527, 0.04583887,\n",
       "       0.03661203, 0.03443985, 0.05655307, 0.04550967, 0.05696223,\n",
       "       0.04160795, 0.02941612, 0.03359009, 0.1680105 , 0.05802768,\n",
       "       0.05114905, 0.03554906, 0.04161119, 0.03872193, 0.05204432,\n",
       "       0.04555544, 0.04441777, 0.07695249, 0.05702252, 0.05560432,\n",
       "       0.08590925, 0.05562363, 0.04793503, 0.04564126, 0.03409676,\n",
       "       0.02584282, 0.0576645 , 0.03681019, 0.08112852, 0.04786601,\n",
       "       0.04396261, 0.05746253, 0.03705553, 0.05922002, 0.05112456,\n",
       "       0.04040848, 0.0502683 , 0.03387181, 0.05709669, 0.04287119,\n",
       "       0.0708317 , 0.0901138 , 0.09060359, 0.07192618, 0.07002839,\n",
       "       0.05748618, 0.03576018, 0.03350966, 0.05248703, 0.05796731,\n",
       "       0.06801189, 0.6601299 , 0.12713635, 0.04161382, 0.22361718,\n",
       "       0.04700445, 0.09040166, 0.04043517, 0.05058243, 0.04468286,\n",
       "       0.0325975 , 0.03483305, 0.02818176, 0.06556109, 0.04510109,\n",
       "       0.07702189, 0.05458917, 0.07517961, 0.03717499, 0.05288805,\n",
       "       0.04795526, 0.05573194, 0.06475613, 0.04739873, 0.04307963,\n",
       "       0.03605414, 0.13843769, 0.0853437 , 0.12748158, 0.04733627,\n",
       "       0.08107036, 0.05102096, 0.05896306, 0.07118903, 0.06067625,\n",
       "       0.06728484, 0.05322087, 0.37148055, 0.06085177, 0.07232028,\n",
       "       0.06615356, 0.09997804, 0.06394334, 0.0916421 , 0.04502976,\n",
       "       0.0820341 , 0.04879506, 0.0409804 , 0.03725337, 0.04368143,\n",
       "       0.03915275, 0.05607507, 0.06149605, 0.03974561, 0.07240452,\n",
       "       0.1599009 , 0.06891471, 0.07251713, 0.04230036, 0.05764881,\n",
       "       0.03480799, 0.06595187, 0.0721779 , 0.0473187 , 0.05536715,\n",
       "       0.08110299, 0.03693042, 0.04905362, 0.0470282 , 0.0475199 ,\n",
       "       0.03614943, 0.05550628, 0.11536495, 0.06860514, 0.07230347,\n",
       "       0.05728071, 0.23767145, 0.04335469, 0.07080276, 0.04932894,\n",
       "       0.18984514, 0.06667496, 0.08830231, 0.04889848, 0.04293713,\n",
       "       0.0525255 , 0.03754187, 0.04543408, 0.04202267, 0.14925307,\n",
       "       0.05611324, 0.04208295, 0.0638619 , 0.20806387, 0.07486637,\n",
       "       0.32987607, 0.06203106, 0.08131549, 0.05485875, 0.17123628,\n",
       "       0.06973745, 0.04911255, 0.05690204, 0.10510549, 0.03948237,\n",
       "       0.05683893, 0.05185908, 0.04230393, 0.04696732, 0.16764848,\n",
       "       0.05917481, 0.06710176, 0.03573446, 0.04614304, 0.17316617,\n",
       "       0.07437512, 0.04480107, 0.06348024, 0.05244746, 0.03496759,\n",
       "       0.04904475, 0.04141937, 0.04649651, 0.05319756, 0.07194245,\n",
       "       0.05593311, 0.06653887, 0.06066245, 0.08479983, 0.07512007,\n",
       "       0.08813259, 0.05142972, 0.1562676 , 0.07739004, 0.05763689,\n",
       "       0.05724613, 0.10614148, 0.04948803, 0.06611218, 0.05632121,\n",
       "       0.05427594, 0.05549333, 0.05507302, 0.04810137, 0.0681743 ,\n",
       "       0.049611  , 0.07311644, 0.05338112, 0.05319913, 0.05079652,\n",
       "       0.06070992, 0.06133796, 0.04280087, 0.08035365, 0.03631262,\n",
       "       0.07827458, 0.03052569, 0.13535257, 0.39630482, 0.14215666,\n",
       "       0.11453454, 0.06324589, 0.07333033, 0.08732206, 0.07257804,\n",
       "       0.04978888, 0.08880438, 0.06457475, 0.04953563, 0.1445941 ,\n",
       "       0.09351829, 0.07005353, 0.10499208, 0.07641257, 0.20869742,\n",
       "       0.06595601, 0.05303091, 0.06791276, 0.05899173, 0.09542388,\n",
       "       0.04523174, 0.05971973, 0.05981713, 0.04683103, 0.12161333,\n",
       "       0.07971393, 0.03527198, 0.05705748, 0.10966235, 0.06960469,\n",
       "       0.05220345, 0.04830389, 0.05925027, 0.03956387, 0.0574174 ,\n",
       "       0.04897765, 0.06061701, 0.07656032, 0.05141755, 0.05226545,\n",
       "       0.04308926, 0.04894401, 0.04971824, 0.04290951, 0.05691593,\n",
       "       0.05262011, 0.05428067, 0.11947932, 0.04783556, 0.03358729,\n",
       "       0.05583341, 0.16314238, 0.16863534, 0.12950638, 0.07751551,\n",
       "       0.08906693, 0.19280142, 0.08364326, 0.10372125, 0.07884742,\n",
       "       0.05990855, 0.06091027, 0.08919898, 0.07404548, 0.06264456,\n",
       "       0.08696249, 0.1051838 , 0.03245381, 0.06125733, 0.07360888,\n",
       "       0.05466053, 0.06830752, 0.0731751 , 0.05332813, 0.04411197,\n",
       "       0.05230024, 0.05243336, 0.0578489 , 0.05197486, 0.07672881,\n",
       "       0.04123073, 0.04230509, 0.06445363, 0.05878987, 0.05930431,\n",
       "       0.0455924 , 0.05235026, 0.06171576, 0.04958816, 0.05564896,\n",
       "       0.05639136, 0.08363728, 0.13543168, 0.10851248, 0.0523579 ,\n",
       "       0.03740046, 0.04553289, 0.08275602, 0.09347362, 0.0868569 ,\n",
       "       0.06515075, 0.07140927, 0.07011706, 0.06170375, 0.07983036,\n",
       "       0.04739572, 0.06758764, 0.05729391, 0.0611944 , 0.08488432,\n",
       "       0.07690142, 0.11450015, 0.05079628, 0.05775212, 0.05974397,\n",
       "       0.04812571, 0.03685494, 0.05512166, 0.05733675, 0.06055477,\n",
       "       0.08519164, 0.20506167, 0.06099753, 0.0589749 , 0.09190553,\n",
       "       0.06278227, 0.06426202, 0.06251699, 0.07267146, 0.04269539,\n",
       "       0.06615906, 0.0587    , 0.08639249, 0.05713341, 0.04353198,\n",
       "       0.04556146, 0.11612605, 0.03856017, 0.04218445, 0.1658479 ,\n",
       "       0.06987675, 0.07045704, 0.33519083, 0.09034045, 0.07140362,\n",
       "       0.10674044, 0.07369295, 0.7748416 , 0.56480706, 0.17594078,\n",
       "       0.10301205, 0.08586742, 0.07113925, 0.0739236 , 0.09480888,\n",
       "       0.07864599, 0.0530353 , 0.09724239, 0.05375975, 0.05320658,\n",
       "       0.07226597, 0.07158456, 0.14013642, 0.0805452 , 0.10767572,\n",
       "       0.1371655 , 0.03641427, 0.07223266, 0.05920517, 0.07258307,\n",
       "       0.05637302, 0.07928726, 0.08665177, 0.04956963, 0.04465184,\n",
       "       0.06883135, 0.04163955, 0.41029868, 0.43562976, 0.05037854,\n",
       "       0.10826544, 0.04967061, 0.05849574, 0.0401689 , 0.0408391 ,\n",
       "       0.05801131, 0.05291194, 0.40238076, 0.04522796, 0.07741116,\n",
       "       0.06616253, 0.05429222, 0.0570279 , 0.16481628, 0.05506832,\n",
       "       0.0465851 , 0.07227284, 0.06837714, 0.05162508, 0.06080741,\n",
       "       0.06615567, 0.06898757, 0.07447354, 0.06098381, 0.04339648,\n",
       "       0.1107439 , 0.0741659 , 0.05333447, 0.06850012, 0.10204318,\n",
       "       0.06191745, 0.05597766, 0.07643506, 0.10902235, 0.02971146,\n",
       "       0.04974082, 0.14524744, 0.03559296, 0.08459207, 0.08297872,\n",
       "       0.1648114 , 0.07836824, 0.1077728 , 0.08860919, 0.08036447,\n",
       "       0.07205038, 0.0777083 , 0.4941057 , 0.56762284, 0.13464764,\n",
       "       0.07352422, 0.0780955 , 0.08579404, 0.31980515, 0.0603017 ,\n",
       "       0.16304061, 0.12872238, 0.06851431, 0.05881047, 0.06423424,\n",
       "       0.05142625, 0.07399525, 0.05235464, 0.04798631, 0.05121996,\n",
       "       0.06680971, 0.06742518, 0.07894549, 0.09385133, 0.06438035,\n",
       "       0.08211641, 0.06648213, 0.16856068, 0.07832322, 0.07149744,\n",
       "       0.1077076 , 0.06967971, 0.12666991, 0.09862227, 0.13203081,\n",
       "       0.06338015, 0.08012588, 0.11676636, 0.11471304, 0.059166  ,\n",
       "       0.04970394, 0.06420961, 0.10829389, 0.1318441 , 0.07665187,\n",
       "       0.05666748, 0.09796901, 0.07728666, 0.06161549, 0.0648257 ,\n",
       "       0.07983685, 0.16797297, 0.04588093, 0.05474375, 0.10029035,\n",
       "       0.05540468, 0.04196225, 0.05166675, 0.06261787, 0.07512298,\n",
       "       0.09169231, 0.06588341, 0.04758233, 0.19441816, 0.10878013,\n",
       "       0.0437239 , 0.07443503, 0.05871604, 0.0553655 , 0.07981548,\n",
       "       0.04336967, 0.05203718, 0.0777353 , 0.08576708, 0.04331046,\n",
       "       0.06524567, 0.07691845, 0.07874694, 0.05351444, 0.10298971,\n",
       "       0.04893059, 0.1000389 , 0.39069217, 0.07802455, 0.5793409 ,\n",
       "       0.13237959, 0.10005176, 0.589824  , 0.1150474 , 0.07390653,\n",
       "       0.07794634, 0.11535105, 0.11287688, 0.10803406, 0.07381602,\n",
       "       0.10975315, 0.08237883, 0.06182948, 0.15826365, 0.18105794,\n",
       "       0.16672787, 0.09312245, 0.11249278, 0.26229274, 0.08607739,\n",
       "       0.05389742, 0.08683811, 0.1184164 , 0.05666901, 0.26935035,\n",
       "       0.10722616, 0.09854537, 0.13102013, 0.19570923, 0.11017065,\n",
       "       0.08991355, 0.05005249, 0.06545471, 0.10748033, 0.15730654,\n",
       "       0.08655958, 0.10530155, 0.05191512, 0.06345069, 0.05518939,\n",
       "       0.111292  , 0.3479951 , 0.06806342, 0.07720833, 0.04655397,\n",
       "       0.06260236, 0.06441249, 0.09645457, 0.13720968, 0.12312203,\n",
       "       0.1272005 , 0.09512283, 0.05161095, 0.08099902, 0.06683844,\n",
       "       0.05812728, 0.07028884, 0.07159825, 0.0420441 , 0.08688754,\n",
       "       0.14096421, 0.05608486, 0.06035679, 0.06861071, 0.09932089,\n",
       "       0.7214526 , 0.1977371 , 0.46264455, 0.79963076, 0.06778387,\n",
       "       0.10587265, 0.07396962, 0.07206617, 0.11108717, 0.08553779,\n",
       "       0.11676899, 0.17153853, 0.23832515, 0.11958853, 0.20685196,\n",
       "       0.1262435 , 0.08498671, 0.25480357, 0.21768129, 0.13029648,\n",
       "       0.09010795, 0.10299715, 0.09908984, 0.07037729, 0.05521854,\n",
       "       0.03769201, 0.10679966, 0.19299692, 0.11873726, 0.14191905,\n",
       "       0.19551001, 0.07348452, 0.08329858, 0.10545732, 0.08693431,\n",
       "       0.06978203, 0.26825726, 0.4834294 , 0.34490114, 0.1872619 ,\n",
       "       0.6183661 , 0.3641303 , 0.19776523, 0.11249766, 0.11767225,\n",
       "       0.1588125 , 0.12799206, 0.25589198, 0.14520422, 0.14654121,\n",
       "       0.11030947, 0.15847781, 0.16707751, 0.08004314, 0.10570505,\n",
       "       0.1559969 , 0.16205113, 0.09667229, 0.10257663, 0.09201604,\n",
       "       0.11639709, 0.2216386 , 0.20483232, 0.1976181 , 0.06136847,\n",
       "       0.11146806, 0.08094352, 0.099264  , 0.08163689, 0.09103683,\n",
       "       0.07174951, 0.14640479, 0.09065531, 0.4781788 , 0.6769904 ,\n",
       "       0.5873227 , 0.36279958, 0.22913004, 0.11395044, 0.40062335,\n",
       "       0.26872963, 0.47614393, 0.11107609, 0.1242491 , 0.20314878,\n",
       "       0.19677407, 0.514555  , 0.1427732 , 0.288042  , 0.13905323,\n",
       "       0.5489392 , 0.24090594, 0.16235554, 0.094836  , 0.07063041,\n",
       "       0.14940485, 0.19677404, 0.34495413, 0.1571627 , 0.5160824 ,\n",
       "       0.4305889 , 0.23033252, 0.5673315 , 0.16382575, 0.16642284,\n",
       "       0.14185423, 0.6675485 , 0.14425984, 0.16424114, 0.19677404,\n",
       "       0.15129477, 0.16771564, 0.13042548, 0.62443364, 0.11281814,\n",
       "       0.23627171, 1.3406198 , 1.2168024 , 0.9025289 , 0.3263325 ,\n",
       "       0.26645344, 0.43102908, 0.52504325, 0.51619375, 0.24051633,\n",
       "       0.40683165, 0.2641532 , 0.21432403, 1.2920978 , 0.23701218,\n",
       "       0.24269333, 0.19822904, 0.5138443 , 0.81345606, 0.29452923,\n",
       "       0.3696651 , 1.2168025 , 0.6659394 , 1.2920978 , 0.19356234,\n",
       "       0.23340115, 0.12222888, 0.28383628, 0.6659394 , 0.10966862,\n",
       "       0.2470626 , 1.2920978 , 0.7330787 , 0.1638945 , 0.56207335,\n",
       "       0.25996605, 1.2168024 , 0.1653979 , 0.39534807, 0.51700926,\n",
       "       0.16222566, 0.31008917, 0.44219956, 0.21488412, 0.42633417,\n",
       "       0.43102908, 0.17197968, 0.12426312, 0.10779636, 0.17150444,\n",
       "       0.16085646, 0.4575113 , 0.25996605, 0.20733753, 0.1602689 ,\n",
       "       0.17076617, 0.19893152, 0.62775993, 0.58141094, 0.1914258 ,\n",
       "       0.48773313, 0.13009048], dtype=float32)"
      ]
     },
     "execution_count": 897,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevance = dist.sum(axis=1)\n",
    "relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "id": "b25bb842-ea56-4c52-982f-49ea30eb3453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 12 13]\n",
      "[0.17190629 0.13997538 0.10424098]\n"
     ]
    }
   ],
   "source": [
    "relevance_threshold = 0.1\n",
    "# relevance_mask = jnp.count_nonzero(relevance > relevance_threshold)\n",
    "# relevance_mask[0]\n",
    "# relevant_kw = (relevance > relevance_threshold).nonzero()[0]\n",
    "filtered_relevance = (relevance > relevance_threshold) * relevance\n",
    "relevant_kw = jnp.where(filtered_relevance != 0)[0]\n",
    "kw_relevance = filtered_relevance[relevant_indices]\n",
    "print(relevant_indices[:3])\n",
    "print(kw_relevance[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "id": "8c1ab722-3bab-411c-8899-f3dd118e3677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (271, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>term</th><th>paper_ids</th><th>count</th><th>paper_count</th><th>relevance</th></tr><tr><td>u32</td><td>str</td><td>list[i64]</td><td>u32</td><td>u32</td><td>f32</td></tr></thead><tbody><tr><td>10</td><td>&quot;construction&quot;</td><td>[277, 494, … 331]</td><td>164</td><td>82</td><td>0.171906</td></tr><tr><td>12</td><td>&quot;industry&quot;</td><td>[295, 372, … 116]</td><td>157</td><td>75</td><td>0.139975</td></tr><tr><td>13</td><td>&quot;smart city&quot;</td><td>[356, 141, … 125]</td><td>179</td><td>73</td><td>0.104241</td></tr><tr><td>30</td><td>&quot;china&quot;</td><td>[264, 92, … 154]</td><td>106</td><td>53</td><td>0.317446</td></tr><tr><td>43</td><td>&quot;effect&quot;</td><td>[401, 238, … 479]</td><td>52</td><td>44</td><td>0.119485</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>867</td><td>&quot;firm green innovation&quot;</td><td>[49, 49, … 49]</td><td>6</td><td>1</td><td>0.62776</td></tr><tr><td>868</td><td>&quot;economic digitalization&quot;</td><td>[2, 2, … 2]</td><td>6</td><td>1</td><td>0.581411</td></tr><tr><td>869</td><td>&quot;dm&quot;</td><td>[216, 216, … 216]</td><td>6</td><td>1</td><td>0.191426</td></tr><tr><td>870</td><td>&quot;high-quality green development&quot;</td><td>[214, 214, … 214]</td><td>6</td><td>1</td><td>0.487733</td></tr><tr><td>871</td><td>&quot;ua&quot;</td><td>[120, 120, … 120]</td><td>6</td><td>1</td><td>0.13009</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (271, 6)\n",
       "┌─────┬────────────────────────────────┬───────────────────┬───────┬─────────────┬───────────┐\n",
       "│ id  ┆ term                           ┆ paper_ids         ┆ count ┆ paper_count ┆ relevance │\n",
       "│ --- ┆ ---                            ┆ ---               ┆ ---   ┆ ---         ┆ ---       │\n",
       "│ u32 ┆ str                            ┆ list[i64]         ┆ u32   ┆ u32         ┆ f32       │\n",
       "╞═════╪════════════════════════════════╪═══════════════════╪═══════╪═════════════╪═══════════╡\n",
       "│ 10  ┆ construction                   ┆ [277, 494, … 331] ┆ 164   ┆ 82          ┆ 0.171906  │\n",
       "│ 12  ┆ industry                       ┆ [295, 372, … 116] ┆ 157   ┆ 75          ┆ 0.139975  │\n",
       "│ 13  ┆ smart city                     ┆ [356, 141, … 125] ┆ 179   ┆ 73          ┆ 0.104241  │\n",
       "│ 30  ┆ china                          ┆ [264, 92, … 154]  ┆ 106   ┆ 53          ┆ 0.317446  │\n",
       "│ 43  ┆ effect                         ┆ [401, 238, … 479] ┆ 52    ┆ 44          ┆ 0.119485  │\n",
       "│ …   ┆ …                              ┆ …                 ┆ …     ┆ …           ┆ …         │\n",
       "│ 867 ┆ firm green innovation          ┆ [49, 49, … 49]    ┆ 6     ┆ 1           ┆ 0.62776   │\n",
       "│ 868 ┆ economic digitalization        ┆ [2, 2, … 2]       ┆ 6     ┆ 1           ┆ 0.581411  │\n",
       "│ 869 ┆ dm                             ┆ [216, 216, … 216] ┆ 6     ┆ 1           ┆ 0.191426  │\n",
       "│ 870 ┆ high-quality green development ┆ [214, 214, … 214] ┆ 6     ┆ 1           ┆ 0.487733  │\n",
       "│ 871 ┆ ua                             ┆ [120, 120, … 120] ┆ 6     ┆ 1           ┆ 0.13009   │\n",
       "└─────┴────────────────────────────────┴───────────────────┴───────┴─────────────┴───────────┘"
      ]
     },
     "execution_count": 908,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search(col: str, q: str) -> pl.Expr:\n",
    "    return pl.col(col).str.starts_with(q)\n",
    "df_relevant_terms = (\n",
    "    pl.DataFrame([\n",
    "        pl.Series(\"id\", np.array(relevant_kw), dtype=pl.UInt32),\n",
    "        pl.Series(\"relevance\", np.array(kw_relevance))\n",
    "    ]).lazy()\n",
    "    .join(\n",
    "        pl.scan_parquet(df(\"terms_from_subject_abstract_keywords\")),\n",
    "        on=\"id\"\n",
    "    )\n",
    "    .select(\"id\", \"term\", \"paper_ids\", \"count\", \"paper_count\", \"relevance\")\n",
    "    # .sort(\"relevance\",descending=True)\n",
    "    # .filter(search(\"term\", \"buil\"))\n",
    ").collect()\n",
    "\n",
    "df_relevant_terms.write_parquet(df(\"relevant_terms\"))\n",
    "\n",
    "df_relevant_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "id": "424f9dde-9632-4c99-8452-00723719620f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (271, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>term</th><th>paper_ids</th><th>count</th><th>paper_count</th><th>relevance</th></tr><tr><td>u32</td><td>str</td><td>list[i64]</td><td>u32</td><td>u32</td><td>f32</td></tr></thead><tbody><tr><td>798</td><td>&quot;]&quot;</td><td>[462, 462, … 462]</td><td>6</td><td>2</td><td>0.196774</td></tr><tr><td>734</td><td>&quot;acceptability&quot;</td><td>[227, 227, … 227]</td><td>11</td><td>3</td><td>0.187262</td></tr><tr><td>749</td><td>&quot;administration&quot;</td><td>[472, 472, … 472]</td><td>7</td><td>3</td><td>0.110309</td></tr><tr><td>573</td><td>&quot;africa&quot;</td><td>[168, 272, … 168]</td><td>7</td><td>6</td><td>0.116766</td></tr><tr><td>738</td><td>&quot;air quality&quot;</td><td>[219, 298, … 298]</td><td>9</td><td>3</td><td>0.117672</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>724</td><td>&quot;visibility&quot;</td><td>[381, 166, … 166]</td><td>6</td><td>4</td><td>0.192997</td></tr><tr><td>600</td><td>&quot;web&quot;</td><td>[171, 520, … 270]</td><td>6</td><td>6</td><td>0.390692</td></tr><tr><td>467</td><td>&quot;woman&quot;</td><td>[234, 213, … 234]</td><td>15</td><td>7</td><td>0.774842</td></tr><tr><td>766</td><td>&quot;workability&quot;</td><td>[80, 211, … 80]</td><td>6</td><td>3</td><td>0.146405</td></tr><tr><td>780</td><td>&quot;wtp&quot;</td><td>[200, 200, … 199]</td><td>8</td><td>2</td><td>0.196774</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (271, 6)\n",
       "┌─────┬────────────────┬───────────────────┬───────┬─────────────┬───────────┐\n",
       "│ id  ┆ term           ┆ paper_ids         ┆ count ┆ paper_count ┆ relevance │\n",
       "│ --- ┆ ---            ┆ ---               ┆ ---   ┆ ---         ┆ ---       │\n",
       "│ u32 ┆ str            ┆ list[i64]         ┆ u32   ┆ u32         ┆ f32       │\n",
       "╞═════╪════════════════╪═══════════════════╪═══════╪═════════════╪═══════════╡\n",
       "│ 798 ┆ ]              ┆ [462, 462, … 462] ┆ 6     ┆ 2           ┆ 0.196774  │\n",
       "│ 734 ┆ acceptability  ┆ [227, 227, … 227] ┆ 11    ┆ 3           ┆ 0.187262  │\n",
       "│ 749 ┆ administration ┆ [472, 472, … 472] ┆ 7     ┆ 3           ┆ 0.110309  │\n",
       "│ 573 ┆ africa         ┆ [168, 272, … 168] ┆ 7     ┆ 6           ┆ 0.116766  │\n",
       "│ 738 ┆ air quality    ┆ [219, 298, … 298] ┆ 9     ┆ 3           ┆ 0.117672  │\n",
       "│ …   ┆ …              ┆ …                 ┆ …     ┆ …           ┆ …         │\n",
       "│ 724 ┆ visibility     ┆ [381, 166, … 166] ┆ 6     ┆ 4           ┆ 0.192997  │\n",
       "│ 600 ┆ web            ┆ [171, 520, … 270] ┆ 6     ┆ 6           ┆ 0.390692  │\n",
       "│ 467 ┆ woman          ┆ [234, 213, … 234] ┆ 15    ┆ 7           ┆ 0.774842  │\n",
       "│ 766 ┆ workability    ┆ [80, 211, … 80]   ┆ 6     ┆ 3           ┆ 0.146405  │\n",
       "│ 780 ┆ wtp            ┆ [200, 200, … 199] ┆ 8     ┆ 2           ┆ 0.196774  │\n",
       "└─────┴────────────────┴───────────────────┴───────┴─────────────┴───────────┘"
      ]
     },
     "execution_count": 902,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_relevant_terms.sort(\"term\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
